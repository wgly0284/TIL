<details><summary>0106</summary>

# header
1. content

</details>

<details><summary>0107</summary>

# AI 기본

## 전처리

1. 머신러닝
- 정의: 기계가 이미지/영상을 이해하고 분석하는 AI 기술 문야
- 응용분야: 자율주행, 의료영상 정밀 진잔, 지능형 보안 시스템 등
- 파이프라인
  - 전처리: 원시 데이터를 모델이 학습할 수 있게 변환
  - 학습: 모델이 데이터를 보고 가중치를 최적화
  - 성능 평가: 학습된 모델 성능 측정
  - 추론: 학습된 모델이 실제 입력에 대해 결과 생성
  - 후처리: 모델 출력 괄과를 사용자나 서비스가 쓸 수 있게 다듬음

2. 기하학적 변환(Geometric Transformations)
- 이미지 좌표계 조작해 형태, 크기, 위치 변경하는 기술
- 딥러닝 모델은 고정돼 크기의 입력 텐서(Input Tensor)를 요구하는 경우가 많음
- 다양한 원본 이미지를 모델 규격에 맞는 작업이 선행

[핵심기법]
- 크기 조정(Resizing) 및 다운 샘플링
- 비율 유지 패딩(Letterbox Padding)
- 이미지 피라미드(Image Pyramid)


3. 크기 조정(Resizing) 및 다운샘플링
- 대부분 CNN 모델은 구조 상 고정된 입력크기(224*224 or 256*256)의 이미지를 요구
- 다운샘플링
  - 고해상도 이미지를 모델 입력 크기에 맞춰 축소하는 과정
  - 픽셀 정보를 압축하면서 발생하는 정보 손실 최소화
  - 앨리어싱(Aliasing) 현상 방지를 위해 보간법(Interpolation) 적용
- 단순 리사이징의 한계
  - 비율(Aspect Ratio)을 무시하고 강제로 정사각형으로 변환할 경우, 객체 형태가 찌그러지는 기하학적 왜곡 발생
  - 모델이 객체의 고유한 형태적 특징을 학습하는 데에 심각한 방해 요인

4. 비율 유지 패딩(Letterbox padding)
- 왜곡 문제 해결을 위한 기법으로 널리 사용
- 객체 탐지(Object Detection) 모델인 YOLO(You Only Look Once) 시리즈 등에서 표준적으로 채택하는 전처리 방식
- 원본 이미지 종횡비(Aspect Ratio)를 유지한 채, 긴 변을 기준으로 타겟 크기에 맞춰 리사이징 수행
- 객체 실제 비율 보존함으로써 모델이 객체의 현태 정보 정확히 학습하도록 도움
- 텍스트 인식(OCR)이나 정밀한 객체 탐지와 같이 형태 비율이 중요한 과제에서 필수


5. 이미지 피라미드(Image Pyramid)
- 하나의 원본 이미지를 다양한 해상도로 변환해 계층적(Hierarchical)으로 구성하는 기법
- 단일 해상도 입력만으로는 아주 작거나 아주 큰 객체를 동시에 효과적으로 탐지하기 어려운 문제를 해결
- 다중 스케일 학습
  - 이미지 피라미드를 통해 모델은 서로 다른 해상도에서 특징(Feature)을 추출
  - 작은 객체는 고해상도 레이어에서, 큰 객체는 저해상도 레이어에서 탐지하는 FPN(Feature Pyramid Network)구조의 기초
  - 가우시안 블러(Gaussian Blur)와 서브 샘플링을 반복해 피라미드를 구축하는 것이 일반적


6. 광도 및 색상 변환(Photometric & Color Transformations)
- 이미지 픽셀 값(Intensity) 자체를 조정해 조명 변화, 색상 왜곡, 노이즈 등 환경적 요인에 대한 모델의 강건성(Robustness)을 높이는 과정
- 강건성: 입력 데이터에 예기치 못한 변화(*Perturbation)나 노이즈가 발생하더라도 모델이 일관성을 유지하는 능력


[핵심기법]
- 정규화
- 색상 보정 및 공간 변환
- 노이즈 제거


7. 정규화(Normalization)
- 디지털 이미지는 통상 0에서 255 사이의 정수 값을 가짐
- 신경망은 입력 데이터의 스케일에 매우 민감해, 큰 값의 입력은 학습 과정에서 내부 공변량 변화(Internal Covalriate Shift)를 유발하거나 최적화 과정을 불안정하게 할 수 있음

[핵심기법]
- 스케일링(Scaling): 픽셀 값을 255로 나눠 0과 1 사이의 실수 범위로 변환, 연산의 수치적 안정성 높임
- 표준화(Standardization): 각 채널(RGB) 별로 데이터 평균 빼고 표준편차로 나눠, 데이터 분포를 평균 0, 분산 1인 표준정규분포로 근사시킴


8. 색상 보정 및 공간 변환
- 동일한 객체라도 조명 온도(color temperature), 밝기, 그림자에 따라 픽셀값(RGB)이 왜곡됨
- 조명 변화에 흔들리지 않는 데이터 일관성(Consistency) 확보

[핵심기법]
- 히스토그램 평활화: 한쪽으로 쏠린 명암 분포를 균일하게 펼침
- 색상 공간 변환
  - 밝기와 색상 성분 분리
  - V(명도) 채널만 조절해 강건한(Robust) 모델 학습 및 데이터 증강

9. 노이즈 제거
- 저조도 환경(Low light), 센서 열잡음(Thermal Noise) 등으로 불가피하게 발생
- 모델이 학습해야 할 핵심인 **고주파 성분(High Frequency: Edge, Texture)**을 훼손해 학습 방해

[핵심기법]
- 가우시안 필터
- 중간값 필터


10. 데이터 증강(Data Augmentation) 전략
- 한정된 학습 데이터에 인위적인 변형을 가해 데이터의 양과 다양성을 늘리는 기법
- 훈련 데이터의 특정 패턴만 외우는 과적합 방지
- 보지 못한 데이터에 대한 일반화(Gerneralization) 성능 극대화

[핵심기법]
- 기하학적 증강
- 광도적 증강/커널 기반 증강
- 고급 증강
  - Mosaic
  - Mixup
  - CutMix
  

## 추론



## 후처리

</details>


<details><summary>0108</summary>

### AI 아카이브 시스템 실습

### 주요 내용

1. 실행 방법
```bash
# 의존성 설치
pip install -r requirements.txt

# 애플리케이션 실행
streamlit run app.py
```

2.  사용 방법
- http://localhost:8501 접속
- **문서 업로드 탭**
   - PNG, JPG, JPEG 형식의 문서 이미지 업로드
   - 자동으로 문서 유형 분류 및 정보 추출
   - "저장" 버튼으로 데이터베이스에 보관
- **문서 검색 탭**
   - 벡터 유사도 검색 또는 키워드 검색 선택
   - 검색어 입력 (예: "영수증", "계약서")
   - 검색 결과에서 이미지 미리보기 및 다운로드
- **문서 목록 탭**
   - 저장된 모든 문서 목록 확인
   - 각 문서의 상세 정보 열람

### 주요 기능
- DiT 기반 문서 유형 자동 분류 
- PaddleOCR 한국어 텍스트 추출 및 위치 검출
- Donut 모델 영수증 정보 자동 구조화
- LayoutLMv3 문서 레이아웃 분석 및 정보 추출
- Ko-SRoBERTa 벡터 임베딩 기반 의미 검색
- KoBART 한국어 문서 자동 요약
- SQLModel + SQLite 문서 메타데이터 관리
- Streamlit 웹 기반 사용자 인터페이스

</details>

<details><summary>0109</summary>

# 
1. 프로토콜
 1) 개념: 네트워크에서 컴퓨터, 스무트폰, 서버들이 서로 데이터를 주고 받기 위해 미리 정한 약속 혹은 규칙.

```
예시)
전화오면 받는다 -> 인사한다 -> 이야기 순서를 지킨다 -> 끊을 때 인사한다
```

 2) 3대 요소


  | 요소 | 설명 | 예시 |
 | --- | --- | --- |
 | 구문(syntax) | 데이터 모양 | '안녕'은 UTF-8, 3바이트 |
 | 의미(Semantics) | 무슨 뜻인지 | 'GET' = 데이터 달라고 함 |
 | 타이밍(Timing) | 언제, 얼마나 빠르게 | 1초에 100바이트 |


 3) 네트워크 프로토콜 예시

 ```
 📧 HTTP    → 웹페이지 요청/응답 규칙
💬 WebSocket → 실시간 채팅 규칙  
📹 WebRTC  → 화상통화 연결 규칙
📨 TCP     → 데이터 안전 전달 규칙
⚡ UDP     → 빠른 데이터 전달 규칙
 ```

 4) 중요한 이유
 ```
 프로토콜 ❌ → 한국어 ↔ 영어 → 일본어 = 통화 불가능
프로토콜 ✅ → 모두 같은 규칙 → 전 세계 통신 가능
 ```

즉, 프로토콜은 **"다른 기기들이 서로 알아듣고 소통할 수 있게 하는 공통 언어"**임.

</details>


<details><summary>0114</summary>

# JIRA 사용법 정리
1. 
  - 에픽: 가장 큰 블록
  - 스프린트: 타임라인(1주) 등 / 
  - 스토리: 요구 사항(큼직한) / 스토리포인트: 난이도. 'GPT딸깍', 혹은 시간 정도로 표시.
  - 테스크: 제일 작은 단위

</details>

<details><summary>0116</summary>

# IT 용어 (2주차) 정리
1. WEB Server
  - 클라이언트가 요청하는 ㅈ어척 컨텐츠(Html, CSS, image, JS 등)을 제공하는 서버

2. WAS(Web Application Server)
  - 동적 컨텐츠를 제공하기 위한 미들웨어 웹 서버로부터 요청이 오면 처리를 진행함.
  - WEB 서버가 처리하는 정척 컨텐츠 제공 가능

3. 정적 컨텐츠(Static Content)
  - 서버에 저장한 걸 그대로 모든 접속자에게 제공해 동일한 화면을 보여주는 형태(Html, CSS, image, JS 등)

4. 동적 컨텐츠(Dynamic Content)
  - 사용자의 정보/상태/요청내용에 따라 다른 결과를 보여주는 형태(JAVA, ASP, JSP, PHP 등)

5. Web Server와 WAS

```
┌─────────────────────┐          ┌──────────────────────────────┐
│     Client          │ Request  │     WAS/Web Application      │
│  ┌──────────────┐   │ ───────▶│     Server                    │
│  │ Mobile App    │   │ Response│ ┌──────────────────────────┐  │
│  │   Browser     │   │ ◀──────  └─▶ Web Container             │
│  └──────────────┘   │          │ │ JSP Servlet              │  │
└─────────────────────┘          │ │ (Dynamic Processing)     │◄─┼─ DB
                                 │ └──────────────┴──────────┘  │
                                 └──────────────────────────────┘
```

6. Web Server와 WAS 분리 이유

  1) 서버 부하 분산 및 성능 최적화

    - 정적 콘텐츠(HTML, CSS, JS, 이미지 등)는 **웹 서버**에서 처리해 빠르게 응답
    - 동적 요청(비즈니스 로직, DB 연동 등)은 WAS에서 처리해서 효율성 극대화

  2) 확장성
    - 웹 서버와 WAS를 독립적으로 확장 가능
    트래픽 증가 시 WAS만 추가해서 효율적 인프라 구성

  3) 보안 강화
    - 웹 서버가 WAS 앞단에서 방어벽 역할 수행
    - 보안 위험을 줄이고 서버 안정성 높임

  4) 관리 및 유지보수 용이
    - 웹 서버와 WAS를 개별적으로 관리하여 유지보수 부담 감소
    - 서비스 장애 발생 시 영향도를 최소화


7. URI & URL & URN 
**URI: 식별, URL: 위치, URN: 이름**

1) URL vs URN vs URI 비교
```
예제1: https://www.charlezz.com/index
┌──────┬──────┬──────┐
│ URL │ URN │ URI │
│ O │ X │ O │
└──────┴──────┴──────┘

예제2: https://www.charlezz.com/index.html
┌──────┬──────┬──────┐
│ URL │ URN │ URI │
│ O │ X │ O │
└──────┴──────┴──────┘
```


</details>

<details><summary>0121</summary>

## 하트비트(Heartbeat) 기법
 컴퓨터 네트워크나 분산 시스템에서 시스템의 구성 요소(노드, 서버, 프로세스)들이 정상적으로 작동 중인지 확인하기 위해 주기적으로 신호를 주고받는 고가용성(High Availability, HA) 기술
  
마치 살아있는 생명체의 심장 박동(Heartbeat)처럼, 구성 요소가 "나는 아직 살아있고 정상적으로 작동 중이다"라는 신호를 마스터 서버나 동료 노드에게 주기적으로 보냄.

1. 동작 원리
- 신호 전송: 노드 A가 설정된 주기(예: 몇 초 단위)로 노드 B 또는 중앙 모니터링 시스템에 "Heartbeat" 패킷(상태 메시지)을 보냄.

- 응답 대기: 수신 측은 해당 패킷을 받아 노드 A가 정상임을 확인합니다.
- 장애 감지: 만약 정해진 시간 동안 하트비트 신호가 수신되지 않으면(Timeout), 수신 측은 해당 노드가 장애(Down) 상태이거나 네트워크에서 연결이 끊긴 것으로 간주.
자동 복구(Failover): 장애가 감지되면, 시스템은 자동으로 해당 노드의 작업을 다른 예비 노드(Redundant node)로 인계하여 서비스 중단을 막음. 

2. 주요 활용 분야
- 고가용성 클러스터(HA Cluster): 서버 이중화 환경에서 주(Primary) 서버가 죽으면 보조(Secondary) 서버가 즉시 업무를 이어받을 때 사용.
- 분산 시스템(Distributed Systems): 하둡(Hadoop)의 DataNode나 카프카(Kafka)의 컨슈머 그룹에서 각 노드의 생존을 감시.
웹 서비스 모니터링: 로드 밸런싱이 적용된 환경에서 살아있는 웹 서버로만 트래픽을 보내도록 상태를 체크

3. 하트비트의 종류
- Active/Passive Heartbeat: 하나의 노드만 작동하고 다른 노드는 대기하다가, 하트비트가 끊기면 대기 중이던 노드가 작동하는 방식
- Active/Active Heartbeat: 모든 노드가 동시에 작동하며 서로 하트비트를 체크하고, 한 노드 장애 시 남은 노드들이 부하를 분산하는 방식
- 데이터스토어 하트비트: 네트워크가 분리되어(Partitioning) 하트비트가 끊긴 상황인지, 실제로 서버가 죽은 상황인지 구분하기 위해 데이터베이스(Storage)를 통해 신호를 교환하는 방식

4. 장단점


- 장점
  - 장애 신속하게 감지 -> 서비스 다운타임 최소화(고가용성 보장) 
  - 구현이 비교적 단순 & 직관적 
- 단점
  - 네트워크 정체 시 오해 -> 장애로 잘못 판단할 수 있음 
  - False Positive: 네트워크 일시 단절로 인한 잦은 Failover 발생 가능성 有 



5. 관련 용어
- 하트블리드(Heartbleed): 2014년 발견된 OpenSSL의 취약점으로, 하트비트 기능의 구현 오류를 악용하여 서버 메모리 정보를 유출한 보안 사고

하트비트는 현대 IT 인프라에서 서비스의 안정성을 보장하기 위한 필수적인 기술!

</details>

<details><summary>0122</summary>

# header
1. content

</details>

<details><summary>0123</summary>

# header
1. content

</details>